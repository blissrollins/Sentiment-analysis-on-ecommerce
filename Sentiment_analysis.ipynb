{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QO851Xja7TK"
      },
      "outputs": [],
      "source": [
        "#importing the required packages\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "nltk.download('stopwords')\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW45T1QE4dDZ"
      },
      "outputs": [],
      "source": [
        "#reading in the data with pandas library\n",
        "\n",
        "df = pd.read_csv('/content/Reviews.csv', sep ='|')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPLORATORY DATA ANALYSIS AND DATA CLEANING**"
      ],
      "metadata": {
        "id": "VM9zZGICsDLA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9KFNSwz41qP"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzOAM6sV4-7C"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH7EYUPP5JGY"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3R0LDku4-pN"
      },
      "outputs": [],
      "source": [
        "df.dropna(axis=0, how = 'any', subset = ['buyerTranslationFeedback'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psqmvuY65sqL"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2s6oPyy50wE"
      },
      "outputs": [],
      "source": [
        "df.drop(axis = 1, columns = ['buyerName','buyerCountry','buyerFeedback','buyerProductFeedBack','evaluationId','responsiveness','downVoteCount','upVoteCount','evalData','warrantyService','functionality','status'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviews'] = df['buyerTranslationFeedback']\n",
        "df.drop(columns = ['buyerTranslationFeedback'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "aJ4Uem9OsUmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "W5tqpWsXvD5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zl1nF1sbwUb"
      },
      "outputs": [],
      "source": [
        "#defining a function to clean text, it will remove punctuations, tokenize the text and remove stopwords\n",
        "\n",
        "def review_cleaner_string(text):\n",
        "  text_nopunct = ''.join([char for char in text if char not in string.punctuation])\n",
        "  text_tokenized = re.split('\\W+', text_nopunct.lower())\n",
        "  text_nostop = ' '.join([word for word in text_tokenized if word not in nltk.corpus.stopwords.words('english') or word == 'not'])\n",
        "\n",
        "  #stemming words to reduce words to their base word.\n",
        "  ps = nltk.PorterStemmer()\n",
        "  text_stemmed = ' '.join([ps.stem(word) for word in text_nostop.split()])\n",
        "\n",
        "  return text_stemmed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def review_cleaner_token(text):\n",
        "  text_nopunct = ''.join([char for char in text if char not in string.punctuation])\n",
        "  text_tokenized = re.split('\\W+', text_nopunct.lower())\n",
        "  text_nostop = [word for word in text_tokenized if word not in nltk.corpus.stopwords.words('english') or word == 'not']\n",
        "\n",
        "  #stemming words to reduce words to their base word.\n",
        "  ps = nltk.PorterStemmer()\n",
        "  text_stemmed = [ps.stem(word) for word in text_nostop]\n",
        "\n",
        "  return text_stemmed"
      ],
      "metadata": {
        "id": "lIUPxfKcMFkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing cleaning function on random string of characters"
      ],
      "metadata": {
        "id": "Cat4g4KuMFdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8Mgrz3s9WsZ"
      },
      "outputs": [],
      "source": [
        "review_cleaner_string(\"hi, i'm not as bad as you think, running run runner\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_cleaner_token(\"hi, i'm not as bad as you think, running run runner\")"
      ],
      "metadata": {
        "id": "SwwPjcd-MQyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o8Ujps2kD9V"
      },
      "outputs": [],
      "source": [
        "#applying the function to the reviews\n",
        "df['stemmed_reviews'] = df['reviews'].apply(lambda x: review_cleaner_string(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the function to the reviews\n",
        "df['stemmed_reviews_tokens'] = df['reviews'].apply(lambda x: review_cleaner_token(x))"
      ],
      "metadata": {
        "id": "QHtnIrSzMVyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "hyou2-2W1H4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrrMhqfzbC8N"
      },
      "outputs": [],
      "source": [
        "#feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYP92cDrcBAg"
      },
      "outputs": [],
      "source": [
        "df['Evaluation'] = df['Evaluation']/20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgzBvGZdcLxm"
      },
      "outputs": [],
      "source": [
        "df['Evaluation'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQTEU1Llfgds"
      },
      "outputs": [],
      "source": [
        "df['Evaluation'] = df['Evaluation'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHi3dNricmsW"
      },
      "outputs": [],
      "source": [
        "def polarize(x):\n",
        "  if x > 3:\n",
        "    return 'positive'\n",
        "  elif x == 3:\n",
        "    return 'neutral'\n",
        "  else:\n",
        "    return 'negative'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndYR-eAphFzW"
      },
      "outputs": [],
      "source": [
        "df['polarity'] = df['Evaluation'].apply(lambda x: polarize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZombNQMSdZts"
      },
      "outputs": [],
      "source": [
        "df['polarity'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "YeeN74hu_hYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQl3EJ_bhK3h"
      },
      "outputs": [],
      "source": [
        "#data visualization\n",
        "\n",
        "sns.countplot(df, x = 'polarity', palette = 'Set2').set(title = 'No of Reviews for each Polarity Rating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3K-3DJhdyb2"
      },
      "outputs": [],
      "source": [
        "df.drop(columns = ['Evaluation', 'reviews'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOtJTnB_d3g5"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reCSx4gMd8i2"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Flatten the list of word lists into a single list of words\n",
        "all_stemmed = ' '.join([word for word in df['stemmed_reviews']])\n",
        "print(all_stemmed)\n",
        "\n",
        "# Join the words into a single string\n",
        "\n",
        "#Create a word cloud from the lemmas\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_stemmed)\n",
        "\n",
        "# Display the word cloud\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Feedback Lemmatized')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crghj9aUlBRr"
      },
      "outputs": [],
      "source": [
        "counti = len(df.loc[df['polarity']== 'positive'])\n",
        "counti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccYcGZzJksiW"
      },
      "outputs": [],
      "source": [
        "df_positive = df.loc[df['polarity']== 'positive'].sample(594, replace=False)\n",
        "df_neutral = df.loc[df['polarity']== 'neutral']\n",
        "df_negative = df.loc[df['polarity']== 'negative']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM0GYT6IktTh"
      },
      "outputs": [],
      "source": [
        "df_neutral = df.loc[df['polarity']== 'neutral'].sample(594, replace=True)\n",
        "df_negative = df.loc[df['polarity']== 'negative'].sample(594, replace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TqIuWdJkyAp"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df_positive, df_neutral, df_negative])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xuHDQqDkxdZ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnUIAM9xjthv"
      },
      "outputs": [],
      "source": [
        "# Do encoding for Polarity ratings\n",
        "df.loc[df['polarity']== 'negative', 'polarity'] = 0\n",
        "df.loc[df['polarity']== 'neutral', 'polarity'] = 1\n",
        "df.loc[df['polarity']== 'positive', 'polarity'] = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_x4HvJh78KMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the datatype of Polarity_Rating to integer\n",
        "df['polarity'] = df['polarity'].astype('int64')"
      ],
      "metadata": {
        "id": "_ZDP7JaV8J9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K7B33ZDn5QU"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdSjLyxsojDF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIoE3eS-opN8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))  # Set figure size\n",
        "sns.countplot(data=df, x='polarity', palette='viridis')  # Countplot\n",
        "plt.title('Count of Unique Values in polarity')  # Title\n",
        "plt.xlabel('polarity')  # X-axis label\n",
        "plt.ylabel('Count')  # Y-axis label\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ClWMSWUMr2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF8XSu9wvDDD"
      },
      "outputs": [],
      "source": [
        "X = df['stemmed_reviews_tokens']\n",
        "y = df[\"polarity\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42\n",
        ", stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vect = TfidfVectorizer(analyzer = review_cleaner_token)\n",
        "tfidf_vect_fit = tfidf_vect.fit(X_train)\n",
        "Train_X_Tfidf = tfidf_vect_fit.transform(X_train)\n",
        "Test_X_Tfidf = tfidf_vect_fit.transform(X_test)\n"
      ],
      "metadata": {
        "id": "TK86EDdG5cVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a random forest model\n",
        "import time"
      ],
      "metadata": {
        "id": "k7TWEvVd57N-"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators = 50, max_depth= 20, n_jobs= -1,  random_state = 42)\n"
      ],
      "metadata": {
        "id": "_SLA2t7BOa8x"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "rf_model = rf.fit(Train_X_Tfidf, y_train)\n",
        "end_time = time.time()\n",
        "fit_time = (end_time - start_time)"
      ],
      "metadata": {
        "id": "35Hs1KHhOmET"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sorted(zip(rf_model.feature_importances_), reverse = True)[0:10]"
      ],
      "metadata": {
        "id": "RFJYoV8qPhg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "y_pred = rf_model.predict(Test_X_Tfidf)\n",
        "end_time = time.time()\n",
        "pred_time = (end_time - start_time)"
      ],
      "metadata": {
        "id": "HjTgyx_9LNSc"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = score(y_test, y_pred, pos_label=2, average='weighted')"
      ],
      "metadata": {
        "id": "q3oPXF1lQ4yh"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('fit_time: {}/ pred_time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(round(fit_time, 3),\n",
        "                                                                                          round(pred_time, 3),\n",
        "                                                                                          round(precision, 3),\n",
        "                                                        round(recall, 3),\n",
        "                                                        round((y_pred==y_test).sum() / len(y_pred), 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVTWc5WwVOWo",
        "outputId": "5956c800-364a-49ad-8f00-25223bcb5a3b"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time: 0.229/ pred_time: 0.027 ---- Precision: 0.905 / Recall: 0.905 / Accuracy: 0.905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "xBUS3VnHxEm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11, learning_rate = 0.1)\n",
        "\n",
        "start_time = time.time()\n",
        "gb_model = gb.fit(Train_X_Tfidf, y_train)\n",
        "end_time = time.time()\n",
        "fit_time = (end_time - start_time)"
      ],
      "metadata": {
        "id": "UTVovmx-xrSl"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "y_pred_gb = gb_model.predict(Test_X_Tfidf)\n",
        "end_time = time.time()\n",
        "pred_time = (end_time - start_time)"
      ],
      "metadata": {
        "id": "JNS11rqzxs4k"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = score(y_test, y_pred_gb, pos_label=2, average='weighted')"
      ],
      "metadata": {
        "id": "7tMdGsFmzX9X"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('fit_time: {}/ pred_time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(round(fit_time, 3),\n",
        "                                                                                          round(pred_time, 3),\n",
        "                                                                                          round(precision, 3),\n",
        "                                                        round(recall, 3),\n",
        "                                                        round((y_pred_gb==y_test).sum() / len(y_pred), 3)))"
      ],
      "metadata": {
        "id": "aQZcLOfTzq4v",
        "outputId": "5b01791a-82a7-448b-f693-244f31b3bbcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time: 1.844/ pred_time: 0.013 ---- Precision: 0.942 / Recall: 0.941 / Accuracy: 0.941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "md6fU0uqH_fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building a custom grid search"
      ],
      "metadata": {
        "id": "udv40SZeUqS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "param = {'n_estimators': [10, 150, 300],\n",
        "         'max_depth': [10, 20, 30, 60, 90, None]}"
      ],
      "metadata": {
        "id": "fAefsbiTU-wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
        "gs_fit = gs.fit(Train_X_Tfidf, y_train)"
      ],
      "metadata": {
        "id": "4m4YRbJtWEd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
      ],
      "metadata": {
        "id": "qXKrUFh4WgCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv"
      ],
      "metadata": {
        "id": "wI9ZRdkVZEAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_RF(n_est, depth):\n",
        "  rf = RandomForestClassifier(n_estimators = n_est, max_depth= depth, n_jobs= -1,  random_state = 42)\n",
        "  rf_model = rf.fit(Train_X_Tfidf, y_train)\n",
        "  y_pred = rf_model.predict(Test_X_Tfidf)\n",
        "  precision, recall, fscore, support = score(y_test, y_pred, pos_label=2, average='weighted')\n",
        "  print('Est: {}/ Depth: {} ----Precision: {} / Recall: {} / Accuracy: {}'.format(n_est, depth, round(precision, 3),\n",
        "                                                        round(recall, 3),\n",
        "                                                        round((y_pred==y_test).sum() / len(y_pred), 3)))"
      ],
      "metadata": {
        "id": "clngEnuDTaVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n_est in [10, 50, 100]:\n",
        "  for depth in [10, 20, 30, None]:\n",
        "    train_RF(n_est, depth)"
      ],
      "metadata": {
        "id": "QL2O7-6DTaCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_GB(est, max_depth, lr):\n",
        "  gb = GradientBoostingClassifier(n_estimators=est, max_depth=max_depth, learning_rate = lr)\n",
        "  gb_model = gb.fit(Train_X_Tfidf, y_train)\n",
        "  y_pred_gb = gb_model.predict(Test_X_Tfidf)\n",
        "  precision, recall, fscore, support = score(y_test, y_pred_gb, pos_label=2, average='weighted')\n",
        "  print('Est: {}/ Depth: {}/ LR: {} ----Precision: {} / Recall: {} / Accuracy: {}'.format(est, max_depth, lr, round(precision, 3),\n",
        "                                                        round(recall, 3),\n",
        "                                                        round((y_pred_gb==y_test).sum() / len(y_pred), 3)))"
      ],
      "metadata": {
        "id": "kTlACOdEIse7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n_est in [50, 100, 150]:\n",
        "  for max_depth in [3, 7, 11, 15]:\n",
        "    for lr in [0.01, 0.1, 1]:\n",
        "      train_GB(n_est, max_depth, lr)"
      ],
      "metadata": {
        "id": "3B1cPstTQGw-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}